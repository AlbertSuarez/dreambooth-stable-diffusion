{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3GhhZmvhfxS"
      },
      "source": [
        "#⭐ **DreamBooth colab From https://github.com/TheLastBen/fast-stable-diffusion**\n",
        "###🛠️ Notebook adaptado por [@dotcsv](https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🚨 Ten activada la **Aceleración por hardware** con GPU en `\"Entorno de ejecución\" > \"Cambiar tipo de entorno de ejecución\"`"
      ],
      "metadata": {
        "id": "f-BcD0b8hwdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "cUUnmQGHm3a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 1** - Conectamos con Google Drive. **Importante contar con unos 4GB de almacenamiento.**"
      ],
      "metadata": {
        "id": "WCgtpGr6ZOyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Bae3VP6UsE",
        "outputId": "9f65e7ea-737e-4806-9610-afefc744d8f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbKbx185zqlz"
      },
      "source": [
        "### **Paso 2** - Instalamos las librerías necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QyvcqeiL65Tj"
      },
      "outputs": [],
      "source": [
        "#@markdown # Dependencies\n",
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install -q git+https://github.com/TheLastBen/diffusers\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -r /content/usr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1pld5ps87a1q",
        "outputId": "f4238298-b589-4663-aa46-4c41200cb74f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDONE !\n"
          ]
        }
      ],
      "source": [
        "#@markdown # xformers\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('\u001b[1;31mit seems that your GPU is not supported at the moment')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl  \n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDONE !')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 3** - Descargamos el modelo .ckpt de Stable Diffusion original."
      ],
      "metadata": {
        "id": "CnBAZ4eje2Sl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O3KHGKqyeJp9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/\n",
        "#@markdown ---\n",
        "Huggingface_Token = \"\" #@param {type:\"string\"}\n",
        "token=Huggingface_Token\n",
        "\n",
        "#@markdown *(Make sure you've accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5)*\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "CKPT_Path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Or\n",
        "\n",
        "CKPT_gdrive_Link = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if CKPT_Path !=\"\":\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  if os.path.exists(str(CKPT_Path)):\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    with capture.capture_output() as cap: \n",
        "      !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "    !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /content/stable-diffusion-v1-5\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      !rm -r /content/stable-diffusion-v1-5\n",
        "      while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;31mConversion error, check your CKPT and try again')\n",
        "        time.sleep(5)\n",
        "  else:\n",
        "    while not os.path.exists(str(CKPT_Path)):\n",
        "       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n",
        "       time.sleep(5)\n",
        "\n",
        "\n",
        "elif CKPT_gdrive_Link !=\"\":   \n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      !rm -r /content/stable-diffusion-v1-5     \n",
        "    !gdown --fuzzy $CKPT_gdrive_Link -O model.ckpt    \n",
        "    if os.path.exists('/content/model.ckpt'):\n",
        "      if os.path.getsize(\"/content/model.ckpt\") > 1810671599:\n",
        "        !mkdir /content/stable-diffusion-v1-5\n",
        "        with capture.capture_output() as cap: \n",
        "          !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "        !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.ckpt --dump_path /content/stable-diffusion-v1-5\n",
        "        if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "          clear_output()\n",
        "          print('\u001b[1;32mDONE !')\n",
        "          !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "          !rm /content/v1-inference.yaml\n",
        "          !rm /content/model.ckpt\n",
        "        else:\n",
        "          if os.path.exists('/content/v1-inference.yaml'):\n",
        "            !rm /content/v1-inference.yaml\n",
        "          !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "          !rm -r /content/stable-diffusion-v1-5\n",
        "          !rm /content/model.ckpt\n",
        "          while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mConversion error, check your CKPT and try again')\n",
        "            time.sleep(5)\n",
        "      else:\n",
        "        while os.path.getsize('/content/model.ckpt') < 1810671599:\n",
        "           print('\u001b[1;31mWrong link, check that the link is valid')\n",
        "           time.sleep(5)\n",
        "\n",
        "\n",
        "elif token ==\"\":\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "  token=input(\"Insert your huggingface token :\")\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/    \n",
        "    clear_output()\n",
        "    print('\u001b[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "         print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)\n",
        "         \n",
        "elif token !=\"\":\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5   \n",
        "  clear_output()\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/    \n",
        "    clear_output()\n",
        "    print('\u001b[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "         print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 4** - Configuramos el entrenamiento de Dreambooth."
      ],
      "metadata": {
        "id": "Wsp71Ctje5qg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "1pH1oP-7yBZm",
        "outputId": "9286d7cb-5936-40ef-9d00-56e4ea9bfb4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mOK\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "#@markdown ---\n",
        "Training_Subject = \"Character\" #@param [\"Character\", \"Object\", \"Style\", \"Artist\", \"Movie\", \"TV Show\"] \n",
        "\n",
        "With_Prior_Preservation = \"Yes\" #@param [\"Yes\", \"No\"] \n",
        "#@markdown - With the prior reservation method, the results are better, you will either have to upload around 200 pictures of the class you're training (dog, person, car, house ...) or let Dreambooth generate them.\n",
        "\n",
        "MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "\n",
        "Captionned_instance_images = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - Use the keywords included in each instance images as unique instance prompt, this allows to train on multiple subjects at the same time, example : \n",
        "#@markdown - An instance image named fat_dog_doginstancename_in_a_pool.jpg\n",
        "#@markdown - another instance image named a_cat_catinstancename_in_the_woods.png\n",
        "#@markdown - the unique training instance prompts would be : fat dog doginstancename in a pool, a cat doginstancename in the woods\n",
        "#@markdown - at inference you can generate the dog by simply using doginstancename (a random unique identifier) or the cat by catinstancename\n",
        "\n",
        "#@markdown - Also you can enhance the training of a simple subject by simply describing the image using keywords like : smiling, outdoor, sad, lether jacket ...etc\n",
        "\n",
        "#@markdown - If you enable this feature, and want to train on multiple subjects, use the AUTOMATIC1111 colab to generate good quality 512x512 100-200 Class images for each subject (dog and a cat and a cow), then put them all in the same folder and entrer the folder's path in the cell below.\n",
        "\n",
        "#@markdown - If you enable this feature, you must add an instance name and a subject type (dog, man, car) to all the images, separate keywords by an underscore (_).\n",
        "\n",
        "\n",
        "\n",
        "SUBJECT_TYPE = \"person\" #@param{type: 'string'}\n",
        "while SUBJECT_TYPE==\"\":\n",
        "   SUBJECT_TYPE=input('Input the subject type:')\n",
        "\n",
        "#@markdown - If you're training on a character or an object, the subject type would be : Man, Woman, Shirt, Car, Dog, Baby ...etc\n",
        "#@markdown - If you're training on a Style, the subject type would be : impressionist, brutalist, abstract, use \"beautiful\" for a general style...etc\n",
        "#@markdown - If you're training on a Movie/Show, the subject type would be : Action, Drama, Science-fiction, Comedy ...etc\n",
        "#@markdown - If you're training on an Artist, the subject type would be : Painting, sketch, drawing, photography, art ...etc\n",
        "\n",
        "\n",
        "INSTANCE_NAME= \"tu_token_especial\" #@param{type: 'string'}\n",
        "while INSTANCE_NAME==\"\":\n",
        "   INSTANCE_NAME=input('Input the instance name (identifier) :')\n",
        "\n",
        "#@markdown - The instance is an identifier, choose a unique identifier unknown by stable diffusion. \n",
        "\n",
        "INSTANCE_DIR_OPTIONAL=\"\" #@param{type: 'string'}\n",
        "INSTANCE_DIR=INSTANCE_DIR_OPTIONAL\n",
        "while INSTANCE_DIR_OPTIONAL!=\"\" and not os.path.exists(str(INSTANCE_DIR)):\n",
        "    INSTANCE_DIR=input('\u001b[1;31mThe instance folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "\n",
        "#@markdown - If the number of instance pictures is large, it is preferable to specify directly the folder instead of uploading, leave EMPTY to upload.\n",
        "\n",
        "CLASS_DIR=\"/content/data/\"+ SUBJECT_TYPE\n",
        "Number_of_subject_images=500#@param{type: 'number'}\n",
        "while Number_of_subject_images==None:\n",
        "     Number_of_subject_images=input('Input the number of subject images :')\n",
        "SUBJECT_IMAGES=Number_of_subject_images\n",
        "\n",
        "Save_class_images_to_gdrive = False #@param {type:\"boolean\"}\n",
        "#@markdown - Save time in case you're training multiple instances of the same class\n",
        "\n",
        "if Training_Subject==\"Character\" or Training_Subject==\"Object\":\n",
        "  PT=\"photo of \"+INSTANCE_NAME+\" \"+SUBJECT_TYPE\n",
        "  CPT=\"a photo of a \"+SUBJECT_TYPE+\", ultra detailed\"\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"photo of\"\n",
        "elif Training_Subject==\"Style\":\n",
        "  With_Prior_Preservation = \"No\"\n",
        "  PT=\"in the \"+SUBJECT_TYPE+\" style of \"+INSTANCE_NAME\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"in the style of\"  \n",
        "elif Training_Subject==\"Artist\":\n",
        "  With_Prior_Preservation = \"No\"\n",
        "  PT=SUBJECT_TYPE+\" By \"+INSTANCE_NAME\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"by the artist\"  \n",
        "elif Training_Subject==\"Movie\":\n",
        "  PT=\"from the \"+SUBJECT_TYPE+\" movie \"+ INSTANCE_NAME\n",
        "  CPT=\"still frame from \"+SUBJECT_TYPE+\" movie, ultra detailed, 4k uhd\"\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"from the movie\"  \n",
        "elif Training_Subject==\"TV Show\":\n",
        "  CPT=\"still frame from \"+SUBJECT_TYPE+\" tv show, ultra detailed, 4k uhd\"\n",
        "  PT=\"from the \"+SUBJECT_TYPE+\" tv show \"+ INSTANCE_NAME\n",
        "  if Captionned_instance_images:\n",
        "    PT=\"from the tv show\"    \n",
        "  \n",
        "OUTPUT_DIR=\"/content/models/\"+ INSTANCE_NAME\n",
        "\n",
        "if INSTANCE_DIR_OPTIONAL==\"\":\n",
        "  INSTANCE_DIR=\"/content/data/\"+INSTANCE_NAME\n",
        "  !mkdir -p \"$INSTANCE_DIR\"\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    shutil.move(filename, INSTANCE_DIR)\n",
        "    clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "   %cd \"$INSTANCE_DIR\"\n",
        "   !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "   %cd /content\n",
        "print('\u001b[1;32mOK')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 5** - (Opcional) Descargamos imágenes de regularización.  💖 Gracias [Joe Penna](https://github.com/JoePenna/Dreambooth-Stable-Diffusion)!"
      ],
      "metadata": {
        "id": "rYmyuQctfATh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown We’ve created the following image sets\n",
        "#@markdown - `man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
        "#@markdown - `man_unsplash` - pictures from various photographers\n",
        "#@markdown - `person_ddim`\n",
        "#@markdown - `woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
        "#@markdown - `blonde_woman` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
        "\n",
        "dataset=\"person_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"blonde_woman\"]\n",
        "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
        "\n",
        "!mkdir -p regularization_images/{dataset}\n",
        "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset}\n",
        "CLASS_DIR=\"/content/regularization_images/\" + dataset"
      ],
      "metadata": {
        "id": "ze4P8wWPjy7F",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 6** - ...y ahora **¡A ENTRENAR!** 💪"
      ],
      "metadata": {
        "id": "OmIz45s0gH5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1-9QbkfAVYYU",
        "outputId": "2d7315d1-0df5-42ec-bbdb-b36577b82cf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDONE, the CKPT model is in your Gdrive\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "#@markdown  - fp16 or half precision meaning slightly lower quality but double the speed.\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  precision=\"no\"\n",
        "else:\n",
        "  precision=prec\n",
        "\n",
        "Training_Steps=\"1600\" #@param{type: 'string'}\n",
        "#@markdown - Keep it around 1600 to avoid overtraining.\n",
        "\n",
        "Seed=75576 #@param{type: 'number'}\n",
        "\n",
        "#@markdown ---------------------------\n",
        "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "#@markdown - Minimum 200 steps between each save.\n",
        "stp=0\n",
        "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "#@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "Caption=''\n",
        "if Captionned_instance_images:\n",
        "  Caption='--image_captions_filename'\n",
        "\n",
        "if With_Prior_Preservation=='No':\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --train_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --center_crop \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps \n",
        "\n",
        "else:\n",
        "\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --train_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --class_data_dir=\"$CLASS_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "    --instance_prompt=\"$PT\"\\\n",
        "    --class_prompt=\"$CPT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --center_crop \\\n",
        "    --max_train_steps=$Training_Steps \\\n",
        "    --num_class_images=$SUBJECT_IMAGES\n",
        "\n",
        "if Save_class_images_to_gdrive:\n",
        "  if os.path.exists(str(CLASS_DIR)):\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/Class_images'):\n",
        "      !mkdir /content/gdrive/MyDrive/Class_images\n",
        "    Class_gdir= '/content/gdrive/MyDrive/Class_images/'+SUBJECT_TYPE\n",
        "    if not os.path.exists(str(Class_gdir)):\n",
        "      !cp -r \"$CLASS_DIR\" /content/gdrive/MyDrive/Class_images\n",
        "\n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd /content    \n",
        "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "  clear_output()\n",
        "  if precision==\"no\":\n",
        "    !sed -i '226s@.*@@' /content/convertosd.py\n",
        "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "  !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/{INSTANCE_NAME}.ckpt\"@' /content/convertosd.py\n",
        "  !python /content/convertosd.py\n",
        "  clear_output()\n",
        "  if os.path.exists('/content/gdrive/MyDrive/'+INSTANCE_NAME+'.ckpt'):\n",
        "    print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive\")\n",
        "  else:\n",
        "    print(\"\u001b[1;31mSomething went wrong\")\n",
        "else:\n",
        "  print(\"\u001b[1;31mSomething went wrong\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 7** (Opcional) - **Prueba el modelo**\n"
      ],
      "metadata": {
        "id": "Qbclw_Gmg3DC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iAZGngFcI8hq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "\n",
        "Update_repo = False #@param {type:\"boolean\"}\n",
        "\n",
        "INSTANCE__NAME=\"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Leave empty if you want to use the current trained model\n",
        "\n",
        "if INSTANCE__NAME!=\"\":\n",
        "  INSTANCE_NAME=INSTANCE__NAME\n",
        "\n",
        "Use_Custom_Path = False #@param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  if Use_Custom_Path:\n",
        "    del INSTANCE_NAME\n",
        "except:\n",
        "  pass\n",
        "#@markdown - if checked, an input box will ask the full path to a desired model\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  path_to_trained_model='/content/gdrive/MyDrive/'+INSTANCE_NAME+'.ckpt'\n",
        "except:\n",
        "  print('\u001b[1;31mIt seems that you did not perform training during this session \u001b[1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n",
        "  path_to_trained_model=input()\n",
        "     \n",
        "while not os.path.exists(path_to_trained_model):\n",
        "   print(\"\u001b[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
        "   path_to_trained_model=input()\n",
        "\n",
        "         \n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/gdrive/MyDrive/\n",
        "    %mkdir sd\n",
        "    %cd sd\n",
        "    !git clone https://github.com/CompVis/stable-diffusion\n",
        "    !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "    !mkdir -p cache/{huggingface,torch}\n",
        "    %cd /content/\n",
        "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/huggingface ../root/.cache/\n",
        "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/torch ../root/.cache/\n",
        "\n",
        "if Update_repo:\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.sh  \n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/paths.py\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py \n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py\n",
        "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  clear_output()\n",
        "  print('\u001b[1;32m')\n",
        "  !git pull\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:  \n",
        "  if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion/src/k-diffusion/k_diffusion'):\n",
        "    !mkdir /content/gdrive/MyDrive/sd/stable-diffusion/src\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion/src\n",
        "    !git clone https://github.com/CompVis/taming-transformers\n",
        "    !git clone https://github.com/openai/CLIP\n",
        "    !mv /content/gdrive/MyDrive/sd/stable-diffusion/src/CLIP /content/gdrive/MyDrive/sd/stable-diffusion/src/clip\n",
        "    !git clone https://github.com/TencentARC/GFPGAN\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/GFPGAN/gfpgan /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "    !git clone https://github.com/salesforce/BLIP\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/BLIP /content/gdrive/MyDrive/sd/stable-diffusion/src/blip\n",
        "    !git clone https://github.com/sczhou/CodeFormer\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/CodeFormer /content/gdrive/MyDrive/sd/stable-diffusion/src/codeformer\n",
        "    !git clone https://github.com/xinntao/Real-ESRGAN\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/Real-ESRGAN/ /content/gdrive/MyDrive/sd/stable-diffusion/src/realesrgan\n",
        "    !git clone https://github.com/crowsonkb/k-diffusion.git\n",
        "    !cp -r /content/gdrive/MyDrive/sd/stable-diffusion/src/k-diffusion/k_diffusion /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "    !git clone https://github.com/Hafiidz/latent-diffusion\n",
        "    !cp -r  /content/gdrive/MyDrive/sd/stable-diffusion/ldm /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/usr/local/lib/python3.7/dist-packages/gradio-3.4b3.dist-info'):\n",
        "    %cd /content/\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.1\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.2\n",
        "    %mv Dependencies_AUT.1 Dependencies_AUT.7z.001\n",
        "    %mv Dependencies_AUT.2 Dependencies_AUT.7z.002\n",
        "    !7z x Dependencies_AUT.7z.001\n",
        "    time.sleep(2)\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers-4.19.2.dist-info\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers-0.3.0.dist-info\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/accelerate\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/accelerate-0.12.0.dist-info    \n",
        "    !cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "    !rm -r /content/usr\n",
        "    !rm Dependencies_AUT.7z.001\n",
        "    !rm Dependencies_AUT.7z.002\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/ldm/modules\n",
        "    !wget -O attention.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/attention.py\n",
        "    \n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules\n",
        "  !wget -O paths.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/paths.py\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  time.sleep(1)\n",
        "  !wget -O webui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.py\n",
        "  !sed -i 's@gpu_call).*@gpu_call) \\n        demo.queue(concurrency_count=111500)@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/\n",
        "  !wget -O ui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/modules/ui.py\n",
        "  !sed -i 's@css = \"\".*@with open(os.path.join(script_path, \"style.css\"), \"r\", encoding=\"utf8\") as file:\\n        css = file.read()@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py  \n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "  !wget -O style.css https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/style.css\n",
        "  !sed -i 's@min-height: 4.*@min-height: 5.5em;@g' /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css  \n",
        "  %cd /content\n",
        "\n",
        "\n",
        "Use_Gradio_Server = False #@param {type:\"boolean\"}\n",
        "#@markdown  - Only if you have trouble connecting to the local server\n",
        "\n",
        "\n",
        "share=''\n",
        "if Use_Gradio_Server:\n",
        "  share='--share'\n",
        "  !sed -i '1037s@.*@            self.server_name = server_name@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = server_port@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\" if self.local_url.startswith(\"https\") else \"http\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  clear_output()\n",
        "  \n",
        "else:\n",
        "  share=''\n",
        "\n",
        "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "  !sed -i '1037s@.*@            self.server_name = \"{srv[8:]}\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = 443@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "          \n",
        "  !sed -i '13s@.*@    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",@' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "  \n",
        "  !rm /content/srv.txt\n",
        "  !rm /content/srvr.txt\n",
        "  clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion/\n",
        "\n",
        "!python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --disable-safe-unpickle --ckpt \"$path_to_trained_model\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WCgtpGr6ZOyG",
        "bbKbx185zqlz",
        "CnBAZ4eje2Sl",
        "Wsp71Ctje5qg",
        "rYmyuQctfATh",
        "OmIz45s0gH5c",
        "Qbclw_Gmg3DC"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}